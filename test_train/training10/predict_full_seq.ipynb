{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de06ba6d-a13c-48ee-b33a-6be782647ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from globals import *\n",
    "\n",
    "num_files = 270\n",
    "train_prop = 0.9\n",
    "num_epochs = 3000\n",
    "batch_size = 16\n",
    "eval_interval = 100    #how many epochs to train before evaluating model\n",
    "num_estimate = 500    #number of examples to estimate accuracy with\n",
    "lr_start = 3e-4\n",
    "lr_end = lr_start/100\n",
    "mixed_precision = False #train with mixed floating point precision?  helps with GPU memory issues\n",
    "checkpointing = False\n",
    "\n",
    "\n",
    "num_bp = 50_000_000                           # total number of base pairs\n",
    "input_size_processing = \"all\"                 # total number of SNPs in processing\n",
    "input_size_step = 1                           # step between SNPs\n",
    "n_ind_adm = 49 if human_data else 400         # number of individuals in panel file\n",
    "n_ind_pan = 50\n",
    "\n",
    "from processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6b417cf-2314-43b9-bf66-23400f873450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import e, sqrt, log\n",
    "import TNet\n",
    "\n",
    "OHE_values = torch.arange(3**4).reshape(3, 3, 3, 3) # SOI value, ref value, class we are in, labeled class of ref\n",
    "OHE_values[:, :, 2] = torch.flip(OHE_values[:, :, 0], dims=(2,))\n",
    "OHE_values[2] = torch.flip(OHE_values[0], dims=(0,))\n",
    "unique_elements, inverse_indices = torch.unique(OHE_values, return_inverse=True)\n",
    "OHE_values = torch.arange(len(unique_elements))[inverse_indices]\n",
    "OHE_values = OHE_values.flatten()\n",
    "\n",
    "assert n_embd == OHE_values.max() + 1\n",
    "\n",
    "Transition = torch.zeros((num_classes**4, n_embd))\n",
    "Transition[torch.arange(num_classes**4).long(), OHE_values] = 1 #dype = long\n",
    "\n",
    "\n",
    "# how to index:\n",
    "# labeled class + class we are in * 3 + ref_value * 9 + SOI value * 27\n",
    "#    var1              var2                  var3           var4\n",
    "    \n",
    "# if var3_1 == var3_2, var4_1 == var4_2, var2_1 == 2 - var2_2 != 1, var1_1 == 2 - var1_2\n",
    "    # then values should be same\n",
    "# else they should be different\n",
    "\n",
    "class KNet4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        hidden0 = n_embd_model\n",
    "\n",
    "        hidden1 = 1000\n",
    "        hidden2 = 100\n",
    "\n",
    "        hidden3 = 50\n",
    "\n",
    "        self.linear0 = nn.Linear(n_embd_model, hidden0)\n",
    "\n",
    "        self.linear1 = nn.Linear(input_size * hidden0, hidden1)\n",
    "        self.linear2 = nn.Linear(hidden1, hidden2) \n",
    "        self.linear3 = nn.Linear(hidden2, 1)\n",
    "\n",
    "        self.linear4 = nn.Linear((num_classes * n_ind_pan_model), hidden3)\n",
    "        self.linear5 = nn.Linear(hidden3, 1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict_cluster(self, SOI, batch_size=batch_size):\n",
    "\n",
    "        num_individuals, len_seq = SOI.shape\n",
    "\n",
    "        padding = torch.full((num_individuals, input_size // 2), -1).to(device)\n",
    "        SOI = torch.cat((padding, SOI, padding), dim=1) # (num_individuals, len_seq + input_size - 1)\n",
    "        \n",
    "        # fill with 0.25, 0.5, 0.25 # fill with ancestry proporotion\n",
    "        predictions = torch.full((num_individuals, len_seq, num_classes), 1/num_classes).to(device) # (num_individuals, len_seq, num_classes)\n",
    "\n",
    "        ######\n",
    "        # hard coded for 2 ancestries.  # make sure formula is correct\n",
    "        # should be based on positions\n",
    "        ### ChatGPT: The CDF, which gives the probability that a tract length is less than or equal to somve value L, is: F(L) = 1 - e^(-NL)\n",
    "        num_generations = 20 \n",
    "        predictions[0, :, :2] = torch.exp(torch.arange(len_seq) * (-num_generations/100)).unsqueeze(-1).repeat(1,2) * (1/6) + (1/3)\n",
    "        predictions[0, :, 2] = 1 - predictions[0, :, 0] - predictions[0, :, 1]\n",
    "\n",
    "        padding = torch.full((num_individuals, input_size // 2, num_classes), 0).to(device)\n",
    "        predictions = torch.cat((padding, predictions, padding), dim=1) # (num_individuals, len_seq + input_size - 1, num_classes)\n",
    "\n",
    "        mask = (1 - torch.eye(num_individuals)).bool() # is there some way we can make labels a pointer to predictions\n",
    "        refs = SOI.unsqueeze(0).expand(num_individuals,-1,-1)[mask].reshape(num_individuals, num_individuals -1 , len_seq + input_size - 1)\n",
    "        labels = predictions.unsqueeze(0).expand(num_individuals,-1,-1,-1)[mask].reshape(num_individuals, num_individuals - 1, len_seq + input_size - 1, num_classes)\n",
    "\n",
    "        print(\"shapes\")\n",
    "        print(SOI.shape)\n",
    "        print(refs.shape)\n",
    "        print(predictions.shape)\n",
    "        print(labels.shape)\n",
    "\n",
    "        refs2 = torch.zeros(49, 48, 950).to(device)\n",
    "        for i in range(49):\n",
    "            refs2[i] = torch.cat((SOI[:i], SOI[i+1:]), dim=0)\n",
    "        print(torch.equal(refs, refs2))\n",
    "\n",
    "        ####\n",
    "        # while True:\n",
    "        #     for istart in range(1, num_individuals, max_batch_size):\n",
    "        #         iend = min(istart + max_batch_size, num_individuals - 1)\n",
    "        #         out = self(SOI[istart:iend, :input_size], refs[istart:iend, :, :input_size], labels[istart:iend, :, :input_size])\n",
    "        #         predictions[istart:iend, input_size // 2] = F.softmax(out, dim=-1)\n",
    "        #         # right now the forward method chooses 48 random ref panels\n",
    "\n",
    "            \n",
    "            \n",
    "        #     # unnecessary if we can make labels a pointer to predictions\n",
    "        #     # indent/unindent this\n",
    "        #     labels = predictions.unsqueeze(0).expand(num_individuals,-1,-1,-1)[mask].reshape(num_individuals, num_individuals - 1, len_seq + input_size - 1, num_classes)\n",
    "        ####\n",
    "\n",
    "        \"\"\"\n",
    "        improvement:\n",
    "\n",
    "        different way to chooose next predicted index:\n",
    "            structured order\n",
    "            random but based on last time index was predicted\n",
    "            based on how much it changed last time\n",
    "            reinforcement learning specifically for this\n",
    "\n",
    "        include number generations and admixture proportion prediction in the bootstrapping method\n",
    "            use num generations to smooth prediction\n",
    "            use admixture proportion to determine class frequencies\n",
    "            iteratively update these estimates\n",
    "\n",
    "        include smoothing\n",
    "\n",
    "        use posterior probabilities in combination with new predictions\n",
    "            posterior probabilities can be previous predictions and/or class proportions\n",
    "\n",
    "        use positions in model\n",
    "        \n",
    "        \"\"\"\n",
    "            \n",
    "        when_predicted = torch.full((num_individuals, len_seq), float(\"inf\"))\n",
    "        s = 0\n",
    "        for i in range(0, num_individuals * len_seq, batch_size):\n",
    "            ind1 = torch.randint(0, num_individuals, (batch_size,))\n",
    "            ind2 = torch.randint(0, len_seq, (batch_size,))\n",
    "\n",
    "            when_predicted += 1\n",
    "            when_predicted[ind1, ind2] = 0\n",
    "\n",
    "            ind1 = ind1.unsqueeze(-1)\n",
    "            ind2 = ind2.unsqueeze(-1) + torch.arange(input_size).long()\n",
    "            out = self(SOI[ind1, ind2], refs[ind1, :, ind2].transpose(1,2), labels[ind1, :, ind2].transpose(1,2))\n",
    "            out = F.softmax(out, dim=-1)\n",
    "            # torch.stack indices instead?  \n",
    "\n",
    "            s += (predictions[ind1[:,0], ind2[:,0] + input_size // 2] - out).abs().sum().item()\n",
    "            predictions[ind1[:,0], ind2[:,0] + input_size // 2] = out\n",
    "\n",
    "            labels = predictions.unsqueeze(0).expand(num_individuals,-1,-1,-1)[mask].reshape(num_individuals, num_individuals - 1, len_seq + input_size - 1, num_classes)\n",
    "\n",
    "            # if i % 100 == 0:\n",
    "            #     print(i/ (num_individuals * len_seq * 6))\n",
    "            #     print(s/100)\n",
    "            #     print(when_predicted)\n",
    "            #     s = 0\n",
    "\n",
    "\n",
    "        return predictions[:, input_size // 2: -(input_size // 2)]\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def predict_cluster2(self, SOI, positions, batch_size=batch_size, num_generations=None):\n",
    "        \n",
    "        if num_generations is None:\n",
    "            num_generations = 20 #### Change this default value\n",
    "            infer_num_generations = True\n",
    "        else:\n",
    "            infer_num_generations = False\n",
    "\n",
    "        num_individuals, len_seq = SOI.shape\n",
    "\n",
    "        padding = torch.full((num_individuals, input_size // 2), -1).to(device)\n",
    "        SOI = torch.cat((padding, SOI, padding), dim=1) # (num_individuals, len_seq + input_size - 1)\n",
    "        \n",
    "        # fill with 0.25, 0.5, 0.25 # fill with ancestry proporotion\n",
    "        predictions = torch.full((num_individuals, len_seq, num_classes), 1/num_classes).to(device) # (num_individuals, len_seq, num_classes)\n",
    "\n",
    "        predictions[...,[0,2]] = 0.25\n",
    "        predictions[...,1] = 0.5\n",
    "        predictions[0, :, 0] = torch.exp(-num_generations * positions) * (1/4) + (1/4)\n",
    "        # predictions[0, :, 0] = torch.exp(torch.arange(len_seq) * (-num_generations/100)) * (1/4) + (1/4)\n",
    "        predictions[0, :, 1] = 0.5\n",
    "        predictions[0, :, 2] = 1 - predictions[0, :, 0] - predictions[0, :, 1]\n",
    "\n",
    "        padding = torch.full((num_individuals, input_size // 2, num_classes), 0).to(device)\n",
    "        predictions = torch.cat((padding, predictions, padding), dim=1) # (num_individuals, len_seq + input_size - 1, num_classes)\n",
    "\n",
    "        padding = torch.full((input_size // 2,), float(\"inf\")).to(device)\n",
    "        positions = torch.cat((padding, positions / num_bp, padding), dim=0)\n",
    "\n",
    "        mask = (1 - torch.eye(num_individuals)).bool() # is there some way we can make labels a pointer to predictions\n",
    "        refs = SOI.unsqueeze(0).expand(num_individuals,-1,-1)[mask].reshape(num_individuals, num_individuals -1 , len_seq + input_size - 1)\n",
    "        labels = predictions.unsqueeze(0).expand(num_individuals,-1,-1,-1)[mask].reshape(num_individuals, num_individuals - 1, len_seq + input_size - 1, num_classes)\n",
    "\n",
    "        print(\"shapes\")\n",
    "        print(SOI.shape)\n",
    "        print(refs.shape)\n",
    "        print(predictions.shape)\n",
    "        print(labels.shape)\n",
    "\n",
    "        refs2 = torch.zeros(49, 48, 950).to(device)\n",
    "        for i in range(49):\n",
    "            refs2[i] = torch.cat((SOI[:i], SOI[i+1:]), dim=0)\n",
    "        print(torch.equal(refs, refs2))\n",
    "\n",
    "        strict_predictions = predictions.clone()\n",
    "            \n",
    "        when_predicted = torch.full((num_individuals, len_seq), 1.0)\n",
    "        has_predicted = torch.zeros((num_individuals, len_seq))\n",
    "\n",
    "        for i in range(0, num_individuals * len_seq, batch_size):\n",
    "            probabilities = (when_predicted / when_predicted.sum()).flatten()\n",
    "            ind = torch.multinomial(probabilities, batch_size, replacement=False)\n",
    "            \n",
    "            ind1 = ind // len_seq\n",
    "            ind2 = ind % len_seq\n",
    "\n",
    "            ind3, ind4 = ind1.clone(), ind2.clone() #############\n",
    "\n",
    "            # ind1 = torch.randint(0, num_individuals, (batch_size,))\n",
    "            # ind2 = torch.randint(0, len_seq, (batch_size,))\n",
    "\n",
    "            has_predicted[ind1, ind2] = 1\n",
    "\n",
    "            ind1 = ind1.unsqueeze(-1)\n",
    "            ind2 = ind2.unsqueeze(-1) + torch.arange(input_size).long()\n",
    "            SOI_batch = SOI[ind1, ind2]\n",
    "            refs_batch = refs[ind1, :, ind2].transpose(1,2)\n",
    "            labels_batch = labels[ind1, :, ind2].transpose(1,2)\n",
    "            positions_batch = positions.unsqueeze(0).expand(batch_size, -1)[torch.arange(batch_size).long().unsqueeze(-1), ind2]\n",
    "            # torch.stack indices instead?  \n",
    "            params_batch = torch.full((batch_size, 6), num_generations).to(device)\n",
    "\n",
    "            out = self(SOI_batch, refs_batch, labels_batch, positions_batch, params_batch)\n",
    "            out = F.softmax(out, dim=-1) # batch, num_classes\n",
    "\n",
    "            # conider multiplying exp distribution by alpha?\n",
    "            len_exp_distribution = 49 ## this should be chosen based on num generations and threshold accuracy\n",
    "            positions_batch = (positions_batch[:, input_size // 2 - len_exp_distribution // 2: input_size // 2 + len_exp_distribution // 2 + 1] - positions_batch[:, input_size // 2].unsqueeze(-1)).abs()\n",
    "            # The below line is not exactly right.  Each predicted class could transition to another class with different probabilities\n",
    "            exp_distribution = torch.exp(-2 * num_generations * (positions_batch)) # batch, len_exp_distribution\n",
    "\n",
    "            out_smoothed = out.unsqueeze(1) * exp_distribution.unsqueeze(-1) # batch, len_exp_distribution, num_classes\n",
    "            predictions_idx = torch.stack([predictions[ind1[j,0], ind2[j,0] + input_size // 2 - len_exp_distribution // 2: ind2[j,0] + input_size // 2 + len_exp_distribution // 2 + 1] for j in range(batch_size)])\n",
    "            predictions_smoothed = predictions_idx * (1 - exp_distribution.unsqueeze(-1))\n",
    "\n",
    "            for j in range(batch_size):\n",
    "                predictions[ind1[j,0], ind2[j,0] + input_size // 2 - len_exp_distribution // 2: ind2[j,0] + input_size // 2 + len_exp_distribution // 2 + 1] = out_smoothed[j] + predictions_smoothed[j]\n",
    "\n",
    "            labels = predictions.unsqueeze(0).expand(num_individuals,-1,-1,-1)[mask].reshape(num_individuals, num_individuals - 1, len_seq + input_size - 1, num_classes)\n",
    "\n",
    "            #####\n",
    "            strict_predictions[ind3, ind4] = out\n",
    "\n",
    "            if infer_num_generations and i % (batch_size * 100) == 0 and i > 0:\n",
    "\n",
    "                num_tracts = (predictions[:, input_size // 2: -(input_size // 2) - 1].argmax(dim=-1) != predictions[:, input_size // 2 + 1: -(input_size // 2)].argmax(dim=-1)).sum().item() + num_individuals\n",
    "                print(num_tracts)\n",
    "                avg_len_transition = num_individuals * (5.8413e-02 - 5.1200e-06) / num_tracts\n",
    "                print(avg_len_transition)\n",
    "\n",
    "                num_generations = 1 / (4 * avg_len_transition)\n",
    "                print(num_generations)\n",
    "                print()\n",
    "\n",
    "                # total_length = 0\n",
    "                # total_n = 0\n",
    "                # for j in range(num_individuals):\n",
    "                #     positions_valid = positions[input_size // 2 : - (input_size // 2)][has_predicted[j].bool()]\n",
    "                #     predictions_valid = strict_predictions[j, input_size // 2 : - (input_size // 2)][has_predicted[j].bool()].argmax(dim=-1)\n",
    "                #     # print(positions_valid)\n",
    "                #     # print(predictions_valid)\n",
    "                #     transitions = predictions_valid[:-1] != predictions_valid[1:]\n",
    "                #     transition_positions = (positions_valid[:-1][transitions] + positions_valid[1:][transitions]) / 2\n",
    "                #     # this doesn't include first and last ancestry tracts!  Should I include this?\n",
    "                #     tract_lengths = transition_positions[1:] - transition_positions[:-1]\n",
    "                #     total_length += tract_lengths.sum().item()\n",
    "                #     total_n += tract_lengths.shape[0]\n",
    "\n",
    "                # print()\n",
    "                # print(total_length)\n",
    "                # print(total_n)\n",
    "                # num_generations = total_n / (total_length * 4)\n",
    "                # print(num_generations)\n",
    "\n",
    "\n",
    "\n",
    "                continue\n",
    "                from scipy.optimize import curve_fit\n",
    "\n",
    "                def exp_model(dist, a, b, num_generations):\n",
    "                    return (1 - dist) ** num_generations * a + b\n",
    "\n",
    "                print(\"infer num generations\")\n",
    "                # max dist should be based on num generations (current prediction) and threshold\n",
    "                max_dist_valid = 1e-3\n",
    "                all_predictions = predictions[:, input_size // 2 : - (input_size // 2)][has_predicted.bool()]\n",
    "                probs_cov = torch.cov(all_predictions.t())\n",
    "                print(probs_cov)\n",
    "                for j in range(num_individuals):\n",
    "                    positions_predicted = positions[input_size // 2 : - (input_size // 2)][has_predicted[j].bool()]\n",
    "                    distances = positions_predicted.unsqueeze(0) - positions_predicted.unsqueeze(1)\n",
    "                    valid_pairs = (distances > 0) & (distances < max_dist_valid)\n",
    "                    valid_pairs = valid_pairs.nonzero(as_tuple = True)\n",
    "\n",
    "                    # valid_predictions = predictions[j, input_size // 2 : - (input_size // 2)][has_predicted[j].bool()]\n",
    "                    #####\n",
    "                    valid_predictions = strict_predictions[j, input_size // 2 : - (input_size // 2)][has_predicted[j].bool()]\n",
    "                    #we have to account for correlated probabilities\n",
    "                    # we have to update this iteratively. weighted average between new estimate and old estimate where new estimate only includes newer predictions\n",
    "                    probs_same = valid_predictions[valid_pairs[0]] * valid_predictions[valid_pairs[1]]\n",
    "                    valid_distances = distances[valid_pairs]\n",
    "\n",
    "                    valid_pairs_all = distances.abs() < max_dist_valid\n",
    "                    print(valid_pairs_all)\n",
    "\n",
    "                    print(valid_pairs)\n",
    "                    \n",
    "                    y = valid_predictions[:5]\n",
    "                    x = positions_predicted[:5]\n",
    "                    print(y)\n",
    "\n",
    "                    y = y[:, 0].cpu().numpy()\n",
    "                    x = (x - x[0]).cpu().numpy()\n",
    "\n",
    "                    print(x)\n",
    "                    print(y)\n",
    "\n",
    "                    popt, pcov = curve_fit(exp_model, x, y)\n",
    "                    print(popt, pcov)\n",
    "\n",
    "\n",
    "                    exit()\n",
    "\n",
    "                    \n",
    "                # positions_predicted = positions.unsqueeze(0).expand(num_individuals, -1)[:, input_size // 2: -(input_size // 2)][has_predicted.bool()]\n",
    "\n",
    "                # print(positions_predicted.shape)\n",
    "                \n",
    "\n",
    "        return predictions[:, input_size // 2: -(input_size // 2)]\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict_cluster3(self, SOI, positions_bp, recombination_map, len_chrom_bp=None, batch_size=batch_size, num_generations=None, admixture_proportion=None, population_size=None):\n",
    "        \n",
    "        if len_chrom_bp is None:\n",
    "            len_chrom_bp = positions_bp[-1].item() * 2 - positions_bp[-2].item()\n",
    "\n",
    "        len_chrom_morgan = recombination_map(len_chrom_bp)\n",
    "\n",
    "        if num_generations is None:\n",
    "            num_generations = 100 #### Change this default value\n",
    "            infer_num_generations = True\n",
    "        else:\n",
    "            infer_num_generations = False\n",
    "\n",
    "        if admixture_proportion is None:\n",
    "            admixture_proportion = 0.5\n",
    "            infer_admixture_proportion = True\n",
    "        else:\n",
    "            infer_admixture_proportion = False\n",
    "\n",
    "        if population_size is None:\n",
    "            population_size = 10_000\n",
    "\n",
    "        # Then p_0a is the probability that the ancestry assigned class 0 correlates to ancestry A.\n",
    "        # (meaning that it has ancesetry proportion 1 - AP)\n",
    "        p_0a = 0.5\n",
    "        p_2a = 1 - p_0a\n",
    "\n",
    "        num_individuals, len_seq = SOI.shape\n",
    "\n",
    "        padding = torch.full((num_individuals, input_size // 2), -1).to(device)\n",
    "        SOI = torch.cat((padding, SOI, padding), dim=1) # (num_individuals, len_seq + input_size - 1)\n",
    "        \n",
    "        # fill with 0.25, 0.5, 0.25 # fill with ancestry proporotion\n",
    "        predictions = torch.zeros((num_individuals, len_seq, num_classes)).to(device) # (num_individuals, len_seq, num_classes)\n",
    "\n",
    "        positions_morgans = recombination_map(positions_bp)\n",
    "\n",
    "        lam = 2 * population_size * (1 - e ** (-num_generations / (2*population_size)))\n",
    "        lam_a = admixture_proportion * lam\n",
    "        lam_c = (1 - admixture_proportion) * lam\n",
    "\n",
    "        transition_aa_haploid = lam_c / lam + (lam_a/lam) * torch.exp(-lam * positions_morgans) # can make this more efficient by multiplying exps  # change in other locations too\n",
    "        transition_cc_haploid = lam_a / lam + (lam_c/lam) * torch.exp(-lam * positions_morgans)\n",
    "\n",
    "        prob_homozygous = 0.25 ########### (admixture_proportion ** 2 + (1 - admixture_proportion) ** 2) / 2\n",
    "        prob_heterozygous = 0.5 ########### admixture_proportion * (1 - admixture_proportion) * 2\n",
    "        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        # 0.5 0.5 instead of 1 - ap, ap ??!!!\n",
    "        infered_tract0 = 0.5 * (1 - admixture_proportion) * transition_aa_haploid + 0.5 * admixture_proportion * transition_cc_haploid\n",
    "        infered_tract2 = 2 * prob_homozygous - infered_tract0\n",
    "        noninfered_tract0 = (prob_homozygous * num_individuals - infered_tract0) / (num_individuals - 1)\n",
    "        noninfered_tract2 = 2 * prob_homozygous - noninfered_tract0\n",
    "\n",
    "        # predictions[...,[0,2]] = (admixture_proportion ** 2 + (1 - admixture_proportion) ** 2) / 2\n",
    "        # predictions[...,1] = admixture_proportion * (1 - admixture_proportion) * 2\n",
    "\n",
    "        predictions[0, :, 0] = infered_tract0\n",
    "        predictions[0, :, 2] = infered_tract2\n",
    "        predictions[1:, :, 0] = 0.25 #noninfered_tract0.unsqueeze(0).repeat(num_individuals - 1, 1)\n",
    "        predictions[1:, :, 2] = 0.25 #noninfered_tract2.unsqueeze(0).repeat(num_individuals - 1, 1)\n",
    "        predictions[:, :, 1] = 0.5\n",
    "\n",
    "        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        # 0.5 0.5 instead of 1 - ap, ap ??!!!\n",
    "        # predictions[0, :, 0] = 0.5 * (1 - admixture_proportion) * transition_aa_haploid + 0.5 * admixture_proportion * transition_cc_haploid\n",
    "        # predictions[0, :, 2] = 0.5 - predictions[0, :, 0]\n",
    "\n",
    "        padding = torch.full((num_individuals, input_size // 2, num_classes), 0).to(device)\n",
    "        predictions = torch.cat((padding, predictions, padding), dim=1) # (num_individuals, len_seq + input_size - 1, num_classes)\n",
    "\n",
    "        padding = torch.full((input_size // 2,), float(\"inf\")).to(device)\n",
    "        positions = torch.cat((padding, positions_morgans, padding), dim=0)\n",
    "\n",
    "        mask = (1 - torch.eye(num_individuals)).bool() # is there some way we can make labels a pointer to predictions\n",
    "        refs = SOI.unsqueeze(0).expand(num_individuals,-1,-1)[mask].reshape(num_individuals, num_individuals -1 , len_seq + input_size - 1)\n",
    "        labels = predictions.unsqueeze(0).expand(num_individuals,-1,-1,-1)[mask].reshape(num_individuals, num_individuals - 1, len_seq + input_size - 1, num_classes)\n",
    "\n",
    "        print(\"shapes\")\n",
    "        print(SOI.shape)\n",
    "        print(refs.shape)\n",
    "        print(predictions.shape)\n",
    "        print(labels.shape)\n",
    "\n",
    "        refs2 = torch.zeros(num_individuals, num_individuals - 1, len_seq + input_size - 1).to(device)\n",
    "        for i in range(num_individuals):\n",
    "            refs2[i] = torch.cat((SOI[:i], SOI[i+1:]), dim=0)\n",
    "        print(torch.equal(refs, refs2))\n",
    "\n",
    "        strict_predictions = predictions.clone()\n",
    "            \n",
    "        when_predicted = torch.full((num_individuals, len_seq), 1.0)\n",
    "        has_predicted = torch.zeros((num_individuals, len_seq))\n",
    "\n",
    "        for i in range(0, num_individuals * len_seq, batch_size):\n",
    "\n",
    "            # probabilities = (when_predicted / when_predicted.sum()).flatten()\n",
    "            # ind = torch.multinomial(probabilities, batch_size, replacement=False)\n",
    "            # ind1 = ind // len_seq\n",
    "            # ind2 = ind % len_seq\n",
    "\n",
    "            # probabilities = (when_predicted / when_predicted.sum())\n",
    "            if i == 0:\n",
    "                probabilities[0] = 0\n",
    "\n",
    "            probabilities = 1 - predictions[:, input_size // 2 : - (input_size // 2)].max(dim=-1)[0].cpu()\n",
    "            ind1 = torch.multinomial(probabilities.sum(dim=-1), batch_size, replacement=False)\n",
    "            ind2 = torch.multinomial(probabilities[ind1], 1).squeeze(-1)\n",
    "            \n",
    "            ind3, ind4 = ind1.clone(), ind2.clone() #############\n",
    "\n",
    "            # ind1 = torch.randint(0, num_individuals, (batch_size,))\n",
    "            # ind2 = torch.randint(0, len_seq, (batch_size,))\n",
    "\n",
    "            has_predicted[ind1, ind2] = 1\n",
    "\n",
    "            ind1 = ind1.unsqueeze(-1)\n",
    "            ind2 = ind2.unsqueeze(-1) + torch.arange(input_size).long()\n",
    "            SOI_batch = SOI[ind1, ind2]\n",
    "            refs_batch = refs[ind1, :, ind2].transpose(1,2)\n",
    "            labels_batch = labels[ind1, :, ind2].transpose(1,2)\n",
    "            positions_batch = positions.unsqueeze(0).expand(batch_size, -1)[torch.arange(batch_size).long().unsqueeze(-1), ind2]\n",
    "            # torch.stack indices instead?  \n",
    "            params_batch = torch.full((batch_size, 6), num_generations).to(device)\n",
    "\n",
    "            out = self(SOI_batch, refs_batch, labels_batch, positions_batch, params_batch)\n",
    "            out = F.softmax(out, dim=-1).double() # batch, num_classes\n",
    "\n",
    "            ###########9999\n",
    "            positions_diff = (positions - positions_batch[:, input_size // 2].unsqueeze(-1)).abs().to(device) # batch, len_seq + input_size\n",
    "\n",
    "            transition_aa_haploid = lam_c / lam + (lam_a/lam) * torch.exp(-lam * positions_diff) # batch, len_seq + input_size - 1\n",
    "            transition_cc_haploid = lam_a / lam + (lam_c/lam) * torch.exp(-lam * positions_diff)\n",
    "            transition_ac_haploid = 1 - transition_aa_haploid\n",
    "            transition_ca_haploid = 1 - transition_cc_haploid\n",
    "            \n",
    "            transitions = torch.zeros((batch_size, len_seq + input_size - 1, num_classes, num_classes)).double().to(device)\n",
    "            transitions[:, :, 0, 0] = transition_aa_haploid ** 2\n",
    "            transitions[:, :, 0, 1] = transition_aa_haploid * transition_ac_haploid * 2\n",
    "            transitions[:, :, 0, 2] = transition_ac_haploid ** 2\n",
    "            transitions[:, :, 1, 0] = transition_aa_haploid * transition_ca_haploid\n",
    "            transitions[:, :, 1, 1] = transition_aa_haploid * transition_cc_haploid + transition_ac_haploid * transition_ca_haploid\n",
    "            transitions[:, :, 1, 2] = transition_cc_haploid * transition_ac_haploid\n",
    "            transitions[:, :, 2, 0] = transition_ca_haploid ** 2\n",
    "            transitions[:, :, 2, 1] = transition_cc_haploid * transition_ca_haploid * 2\n",
    "            transitions[:, :, 2, 2] = transition_cc_haploid ** 2\n",
    "\n",
    "            out_smoothed = (out.unsqueeze(1).unsqueeze(1) @ transitions).squeeze(-2).float() #@ transition_ancestry_probs\n",
    "            out = out.float()\n",
    "            tmp = torch.exp(-2 * num_generations * positions_diff * 10).unsqueeze(-1) #hardcoded for now #increase factor as time goes on\n",
    "            \n",
    "            predictions[ind3] = predictions[ind3] * (1 - tmp) + out_smoothed * tmp\n",
    "            predictions[:, :input_size // 2] = 0\n",
    "            predictions[:, -(input_size // 2):] = 0\n",
    "\n",
    "            assert ((1 - predictions[:, input_size // 2: - (input_size // 2)].sum(dim=-1)).abs() < 1e-4).all()\n",
    "            ###########9999\n",
    "\n",
    "            ###########9999\n",
    "            # conider multiplying exp distribution by alpha?\n",
    "            # out = out.float()\n",
    "            # len_exp_distribution = 49 ## this should be chosen based on num generations and threshold accuracy\n",
    "            # positions_batch = (positions_batch[:, input_size // 2 - len_exp_distribution // 2: input_size // 2 + len_exp_distribution // 2 + 1] - positions_batch[:, input_size // 2].unsqueeze(-1)).abs()\n",
    "            # # The below line is not exactly right.  Each predicted class could transition to another class with different probabilities\n",
    "            # exp_distribution = torch.exp(-2 * num_generations * (positions_batch)) # batch, len_exp_distribution\n",
    "\n",
    "            # out_smoothed = out.unsqueeze(1) * exp_distribution.unsqueeze(-1) # batch, len_exp_distribution, num_classes\n",
    "            # predictions_idx = torch.stack([predictions[ind1[j,0], ind2[j,0] + input_size // 2 - len_exp_distribution // 2: ind2[j,0] + input_size // 2 + len_exp_distribution // 2 + 1] for j in range(batch_size)])\n",
    "            # predictions_smoothed = predictions_idx * (1 - exp_distribution.unsqueeze(-1))\n",
    "\n",
    "            # for j in range(batch_size):\n",
    "            #     predictions[ind1[j,0], ind2[j,0] + input_size // 2 - len_exp_distribution // 2: ind2[j,0] + input_size // 2 + len_exp_distribution // 2 + 1] = out_smoothed[j] + predictions_smoothed[j]\n",
    "            ###########9999\n",
    "\n",
    "            labels = predictions.unsqueeze(0).expand(num_individuals,-1,-1,-1)[mask].reshape(num_individuals, num_individuals - 1, len_seq + input_size - 1, num_classes)\n",
    "\n",
    "            #####\n",
    "            strict_predictions[ind3, ind4] = out\n",
    "\n",
    "            if infer_num_generations and i % (batch_size * 500) == 0 and i > 0:\n",
    "\n",
    "                predictions_argmax = predictions[:, input_size // 2: -(input_size // 2)].argmax(dim=-1)\n",
    "\n",
    "                positions_diff = positions[input_size // 2: -(input_size // 2)]\n",
    "                positions_diff_start = torch.tensor([(positions_diff[1] - positions_diff[0]) / 2 - 0]).to(device) # this assumes start morgans is 0\n",
    "                positions_diff_end = torch.tensor([len_chrom_morgan - (positions_diff[-1] + positions_diff[-2]) / 2]).to(device)\n",
    "                positions_diff = (positions_diff[2:] - positions_diff[:-2]) / 2\n",
    "                positions_diff = torch.cat((positions_diff_start, positions_diff, positions_diff_end))\n",
    "                positions_diff = positions_diff.unsqueeze(0).expand(num_individuals, -1)\n",
    "\n",
    "                ####\n",
    "                proportion_0 = positions_diff[predictions_argmax == 0].sum().item() / (len_chrom_morgan * num_individuals)\n",
    "                proportion_1 = positions_diff[predictions_argmax == 1].sum().item() / (len_chrom_morgan * num_individuals) \n",
    "                proportion_2 = positions_diff[predictions_argmax == 2].sum().item() / (len_chrom_morgan * num_individuals)\n",
    "\n",
    "                admixture_proportion = proportion_0 + proportion_1 * 0.5 + proportion_2 * 0\n",
    "                ####\n",
    "\n",
    "                #admixture_proportion = 1 - (predictions_argmax.sum().item() / (2 * len(chrom_morgan) * num_indiviudals))\n",
    "\n",
    "\n",
    "                print(admixture_proportion)\n",
    "\n",
    "                transitions = (predictions_argmax[:, :-1] - predictions_argmax[:, 1:])\n",
    "                transitions_diff = transitions.sum().item()\n",
    "                transitions_total = transitions.abs().sum().item() \n",
    "                num_transitions_10 = (transitions_total + transitions_diff) / 2\n",
    "                num_transitions_01 = (transitions_total - transitions_diff) / 2\n",
    "\n",
    "                num_transitions_10_per_morgan = num_transitions_10 / (2 * (1 - admixture_proportion) * len_chrom_morgan * num_individuals)\n",
    "                num_transitions_01_per_morgan = num_transitions_01 / (2 * admixture_proportion * len_chrom_morgan * num_individuals)\n",
    "                predicted_num_generations_10 = -2 * population_size * log(1 - num_transitions_10_per_morgan / (2 * population_size * admixture_proportion))\n",
    "                predicted_num_generations_01 = -2 * population_size * log(1 - num_transitions_01_per_morgan / (2 * population_size * (1 - admixture_proportion)))\n",
    "                \n",
    "                print(predicted_num_generations_10)\n",
    "                print(predicted_num_generations_01)\n",
    "                print()\n",
    "\n",
    "                # num_generations = (predicted_num_generations_01 + predicted_num_generations_10) / 2 \n",
    "\n",
    "                admixture_proportion = 0.5\n",
    "\n",
    "        return predictions[:, input_size // 2: -(input_size // 2)]\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def predict_cluster4(self, SOI, positions_bp, recombination_map, batch_size=batch_size, num_generations=None, admixture_proportion=None, population_size=None):\n",
    "        \n",
    "        if num_generations is None:\n",
    "            num_generations = 20 #### Change this default value\n",
    "            infer_num_generations = True\n",
    "        else:\n",
    "            infer_num_generations = False\n",
    "\n",
    "        if admixture_proportion is None:\n",
    "            admixture_proportion = 0.5\n",
    "            infer_admixture_proportion = True\n",
    "        else:\n",
    "            infer_admixture_proportion = False\n",
    "\n",
    "        if population_size is None:\n",
    "            population_size = 10_000\n",
    "\n",
    "        # Then p_0a is the probability that the ancestry assigned class 0 correlates to ancestry A.\n",
    "        # (meaning that it has ancesetry proportion 1 - AP)\n",
    "        p_0a = 0.5\n",
    "        p_2a = 1 - p_0a\n",
    "\n",
    "        num_individuals, len_seq = SOI.shape\n",
    "\n",
    "        padding = torch.full((num_individuals, input_size // 2), -1).to(device)\n",
    "        SOI = torch.cat((padding, SOI, padding), dim=1) # (num_individuals, len_seq + input_size - 1)\n",
    "        \n",
    "        # fill with 0.25, 0.5, 0.25 # fill with ancestry proporotion\n",
    "        predictions = torch.full((num_individuals, len_seq, num_classes), 1/num_classes).to(device) # (num_individuals, len_seq, num_classes)\n",
    "\n",
    "        positions_morgans = recombination_map(positions_bp)\n",
    "\n",
    "        lam = 2 * population_size * (1 - e ** (-num_generations / (2*population_size)))\n",
    "        lam_a = admixture_proportion * lam\n",
    "        lam_c = (1 - admixture_proportion) * lam\n",
    "\n",
    "        transition_aa_haploid = lam_c / lam + (lam_a/lam) * torch.exp(-lam * positions_morgans) # can make this more efficient by multiplying exps  # change in other locations too\n",
    "        transition_cc_haploid = lam_a / lam + (lam_c/lam) * torch.exp(-lam * positions_morgans)\n",
    "\n",
    "        predictions[...,[0,2]] = (admixture_proportion ** 2 + (1 - admixture_proportion) ** 2) / 2\n",
    "        predictions[...,1] = admixture_proportion * (1 - admixture_proportion) * 2\n",
    "\n",
    "        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        # 0.5 0.5 instead of 1 - ap, ap ??!!!\n",
    "        predictions[0, :, 0] = 0.5 * (1 - admixture_proportion) * transition_aa_haploid + 0.5 * admixture_proportion * transition_cc_haploid\n",
    "        predictions[0, :, 2] = 0.5 - predictions[0, :, 0]\n",
    "\n",
    "        padding = torch.full((num_individuals, input_size // 2, num_classes), 0).to(device)\n",
    "        predictions = torch.cat((padding, predictions, padding), dim=1) # (num_individuals, len_seq + input_size - 1, num_classes)\n",
    "\n",
    "        padding = torch.full((input_size // 2,), float(\"inf\")).to(device)\n",
    "        positions = torch.cat((padding, positions_morgans, padding), dim=0)\n",
    "\n",
    "        mask = (1 - torch.eye(num_individuals)).bool() # is there some way we can make labels a pointer to predictions\n",
    "        refs = SOI.unsqueeze(0).expand(num_individuals,-1,-1)[mask].reshape(num_individuals, num_individuals -1 , len_seq + input_size - 1)\n",
    "        labels = predictions.unsqueeze(0).expand(num_individuals,-1,-1,-1)[mask].reshape(num_individuals, num_individuals - 1, len_seq + input_size - 1, num_classes)\n",
    "\n",
    "        print(\"shapes\")\n",
    "        print(SOI.shape)\n",
    "        print(refs.shape)\n",
    "        print(predictions.shape)\n",
    "        print(labels.shape)\n",
    "\n",
    "        refs2 = torch.zeros(49, 48, 950).to(device)\n",
    "        for i in range(49):\n",
    "            refs2[i] = torch.cat((SOI[:i], SOI[i+1:]), dim=0)\n",
    "        print(torch.equal(refs, refs2))\n",
    "\n",
    "        strict_predictions = predictions.clone()\n",
    "            \n",
    "        when_predicted = torch.full((num_individuals, len_seq), 1.0)\n",
    "        has_predicted = torch.zeros((num_individuals, len_seq))\n",
    "\n",
    "        for i in range(0, num_individuals * len_seq, batch_size):\n",
    "            probabilities = (when_predicted / when_predicted.sum()).flatten()\n",
    "            ind = torch.multinomial(probabilities, batch_size, replacement=False)\n",
    "            \n",
    "            ind1 = ind // len_seq\n",
    "            ind2 = ind % len_seq\n",
    "\n",
    "            ind3, ind4 = ind1.clone(), ind2.clone() #############\n",
    "\n",
    "            # ind1 = torch.randint(0, num_individuals, (batch_size,))\n",
    "            # ind2 = torch.randint(0, len_seq, (batch_size,))\n",
    "\n",
    "            has_predicted[ind1, ind2] = 1\n",
    "\n",
    "            ind1 = ind1.unsqueeze(-1)\n",
    "            ind2 = ind2.unsqueeze(-1) + torch.arange(input_size).long()\n",
    "            SOI_batch = SOI[ind1, ind2]\n",
    "            refs_batch = refs[ind1, :, ind2].transpose(1,2)\n",
    "            labels_batch = labels[ind1, :, ind2].transpose(1,2)\n",
    "            positions_batch = positions.unsqueeze(0).expand(batch_size, -1)[torch.arange(batch_size).long().unsqueeze(-1), ind2]\n",
    "            # torch.stack indices instead?  \n",
    "            params_batch = torch.full((batch_size, 6), num_generations).to(device)\n",
    "\n",
    "            out = self(SOI_batch, refs_batch, labels_batch, positions_batch, params_batch)\n",
    "            out = F.softmax(out, dim=-1) # batch, num_classes\n",
    "\n",
    "            # conider multiplying exp distribution by alpha?\n",
    "            # len_exp_distribution = 49 ## this should be chosen based on num generations and threshold accuracy\n",
    "            # positions_batch = (positions_batch[:, input_size // 2 - len_exp_distribution // 2: input_size // 2 + len_exp_distribution // 2 + 1] - positions_batch[:, input_size // 2].unsqueeze(-1)).abs()\n",
    "            # The below line is not exactly right.  Each predicted class could transition to another class with different probabilities\n",
    "            # exp_distribution = torch.exp(-2 * num_generations * (positions_batch)) # batch, len_exp_distribution\n",
    "\n",
    "            ### Calculate outside of loop\n",
    "            lam = 2 * population_size * (1 - e ** (-num_generations / (2*population_size)))\n",
    "            lam_a = admixture_proportion * lam\n",
    "            lam_c = (1 - admixture_proportion) * lam\n",
    "            transition_ancestry_probs = torch.tensor([[p_0a, 0, p_2a],\n",
    "                                           [0, 1, 0],\n",
    "                                           [p_2a, 0, p_0a]]).to(device)\n",
    "            ###\n",
    "            \n",
    "            # add back in threshold value for longer sequences\n",
    "            positions_diff = (positions - positions_batch[:, input_size // 2].unsqueeze(-1)).abs().to(device) # batch, len_seq + input_size\n",
    "            transition_aa_haploid = lam_c / lam + (lam_a/lam) * torch.exp(-lam * positions_diff) # batch, len_seq + input_size - 1\n",
    "            transition_cc_haploid = lam_a / lam + (lam_c/lam) * torch.exp(-lam * positions_diff)\n",
    "            transition_ac_haploid = 1 - transition_aa_haploid\n",
    "            transition_ca_haploid = 1 - transition_cc_haploid\n",
    "            \n",
    "            transitions_aa_diploid = transition_aa_haploid ** 2\n",
    "            transitions_ab_diploid = transition_aa_haploid * transition_ac_haploid * 2\n",
    "            transitions_ac_diploid = transition_ac_haploid ** 2\n",
    "            transitions_ba_diploid = transition_aa_haploid * transition_ca_haploid\n",
    "            transitions_bb_diploid = transition_aa_haploid * transition_cc_haploid + transition_ac_haploid * transition_ca_haploid\n",
    "            transitions_bc_diploid = transition_cc_haploid * transition_ac_haploid\n",
    "            transitions_ca_diploid = transition_ca_haploid ** 2\n",
    "            transitions_cb_diploid = transition_cc_haploid * transition_ca_haploid * 2\n",
    "            transitions_cc_diploid = transition_cc_haploid ** 2\n",
    "\n",
    "            transitions = torch.zeros((batch_size, len_seq + input_size - 1, num_classes, num_classes)).to(device)\n",
    "            transitions[:, :, 0, 0] = transitions_aa_diploid * p_0a + transitions_cc_diploid * (1 - p_0a)\n",
    "            transitions[:, :, 0, 1] = transitions_ab_diploid * p_0a + transitions_cb_diploid * (1 - p_0a)\n",
    "            transitions[:, :, 0, 2] = transitions_ac_diploid * p_0a + transitions_ca_diploid * (1 - p_0a)\n",
    "            transitions[:, :, 1, 0] = transitions_ba_diploid * p_0a + transitions_bc_diploid * (1 - p_0a)\n",
    "            transitions[:, :, 1, 1] = transitions_bb_diploid\n",
    "            transitions[:, :, 1, 2] = transitions_bc_diploid * p_0a + transitions_ba_diploid * (1 - p_0a)\n",
    "            transitions[:, :, 2, 0] = transitions_ca_diploid * p_0a + transitions_ac_diploid * (1 - p_0a)\n",
    "            transitions[:, :, 2, 1] = transitions_cb_diploid * p_0a + transitions_ab_diploid * (1 - p_0a)\n",
    "            transitions[:, :, 2, 2] = transitions_cc_diploid * p_0a + transitions_aa_diploid * (1 - p_0a)\n",
    "            # transitions[:, :, 0, 0] = transition_aa_haploid ** 2\n",
    "            # transitions[:, :, 0, 1] = transition_aa_haploid * transition_ac_haploid * 2\n",
    "            # transitions[:, :, 0, 2] = transition_ac_haploid ** 2\n",
    "            # transitions[:, :, 1, 0] = transition_aa_haploid * transition_ca_haploid\n",
    "            # transitions[:, :, 1, 1] = transition_aa_haploid * transition_cc_haploid + transition_ac_haploid * transition_ca_haploid\n",
    "            # transitions[:, :, 1, 2] = transition_cc_haploid * transition_ac_haploid\n",
    "            # transitions[:, :, 2, 0] = transition_ca_haploid ** 2\n",
    "            # transitions[:, :, 2, 1] = transition_cc_haploid * transition_ca_haploid * 2\n",
    "            # transitions[:, :, 2, 2] = transition_cc_haploid ** 2\n",
    "\n",
    "            out_smoothed = (out.unsqueeze(1).unsqueeze(1) @ transitions).squeeze(-2) #@ transition_ancestry_probs\n",
    "            predictions[ind3] = predictions[ind3] * (1 - out_smoothed) + out_smoothed\n",
    "            predictions[:, :input_size // 2] = 0\n",
    "            predictions[:, -(input_size // 2):] = 0\n",
    "            # print(out.shape)\n",
    "            # print(transitions.shape)\n",
    "            # print(out_smoothed.shape)\n",
    "            # exit()\n",
    "\n",
    "            ########\n",
    "            # print(transitions[2,ind4[2]+250 + 5,:])\n",
    "            # print(transitions[2,ind4[2]+250 + 250,:])\n",
    "            # transitions[:, :, 0, 0] = transition_aa_haploid ** 2\n",
    "            # transitions[:, :, 0, 1] = transition_aa_haploid * transition_ac_haploid * 2\n",
    "            # transitions[:, :, 0, 2] = transition_ac_haploid ** 2\n",
    "            # transitions[:, :, 1, 0] = transition_aa_haploid * transition_ca_haploid\n",
    "            # transitions[:, :, 1, 1] = transition_aa_haploid * transition_cc_haploid + transition_ac_haploid * transition_ca_haploid\n",
    "            # transitions[:, :, 1, 2] = transition_cc_haploid * transition_ac_haploid\n",
    "            # transitions[:, :, 2, 0] = transition_ca_haploid ** 2\n",
    "            # transitions[:, :, 2, 1] = transition_cc_haploid * transition_ca_haploid * 2\n",
    "            # transitions[:, :, 2, 2] = transition_cc_haploid ** 2\n",
    "            # print(transitions[2,ind4[2]+250 + 5,:])\n",
    "            # print(transitions[2,ind4[2]+250 + 250,:])\n",
    "            #######\n",
    "\n",
    "            labels = predictions.unsqueeze(0).expand(num_individuals,-1,-1,-1)[mask].reshape(num_individuals, num_individuals - 1, len_seq + input_size - 1, num_classes)\n",
    "\n",
    "            #####\n",
    "            strict_predictions[ind3, ind4] = out\n",
    "\n",
    "            # if infer_num_generations and i % (batch_size * 100) == 0 and i > 0:\n",
    "\n",
    "            #     num_tracts = (predictions[:, input_size // 2: -(input_size // 2) - 1].argmax(dim=-1) != predictions[:, input_size // 2 + 1: -(input_size // 2)].argmax(dim=-1)).sum().item() + num_individuals\n",
    "            #     print(num_tracts)\n",
    "            #     avg_len_transition = num_individuals * (5.8413e-02 - 5.1200e-06) / num_tracts\n",
    "            #     print(avg_len_transition)\n",
    "\n",
    "            #     num_generations = 1 / (4 * avg_len_transition)\n",
    "            #     print(num_generations)\n",
    "            #     print()\n",
    "\n",
    "        return predictions[:, input_size // 2: -(input_size // 2)]\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict_full_sequence(self, SOI, refs, labels, max_batch_size=batch_size):\n",
    "        # SOI     #input_size_full\n",
    "        # refs    #n_ind_max, input_size_full\n",
    "        # labels  #n_ind_max, input_size_full\n",
    "\n",
    "        assert SOI.shape[0] == refs.shape[1]\n",
    "        assert refs.shape == labels.shape\n",
    "\n",
    "        full_input_size = refs.shape[1]\n",
    "\n",
    "        padding = torch.ones((input_size // 2,)) * -1 \n",
    "        SOI = torch.cat((padding, SOI, padding), dim=0)\n",
    "        padding = torch.ones((n_ind_max, input_size // 2)) * -1\n",
    "        refs = torch.cat((padding, refs, padding), dim=-1)\n",
    "        labels = torch.cat((padding, labels, padding), dim=-1)\n",
    "\n",
    "        out = torch.zeros((full_input_size, num_classes)).to(device)\n",
    "        for istart in range(0, full_input_size, max_batch_size):\n",
    "            iend = min(istart + max_batch_size, full_input_size) \n",
    "\n",
    "            refs_batch = refs[:,istart:input_size + iend - 1].to(device).unfold(-1, input_size, 1).transpose(0, 1)\n",
    "            labels_batch = labels[:,istart:input_size + iend - 1].to(device).unfold(-1, input_size, 1).transpose(0, 1)\n",
    "            SOI_batch = SOI[istart:input_size + iend - 1].to(device).unfold(0, input_size, 1)\n",
    "\n",
    "            out[istart:iend] = self(SOI_batch, refs_batch, labels_batch)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def forward(self, SOI, refs, labels, positions, params):\n",
    "\n",
    "        # print(SOI.shape, refs.shape, labels.shape)\n",
    "\n",
    "        # SOI             # batch, input_size\n",
    "        # positions       # batch, input_size\n",
    "        # refs            # batch, n_ind_max, input_size\n",
    "        # labels          # batch, n_ind_max, input_size, num_classses\n",
    "\n",
    "        # torch.set_printoptions(threshold=1000)\n",
    "        # print('\\n\\n\\n')\n",
    "        # print(SOI[0, ::2])\n",
    "        # print(positions[0, ::2])\n",
    "        # print(refs[0,0,::2])\n",
    "        # print(labels[0, 0, ::2].sum(dim=-1))\n",
    "\n",
    "        SOI = SOI.long().abs().unsqueeze(1).unsqueeze(1) # batch, 1, 1, input_size\n",
    "\n",
    "\n",
    "        idx = torch.randperm(num_classes * n_ind_pan_model)\n",
    "        refs = refs.long()[:, idx]\n",
    "        labels = labels[:, idx]\n",
    "\n",
    "        # OHE distance with negative value encoding to all 0s\n",
    "        mask1 = (refs < 0)\n",
    "        refs = torch.abs(refs).unsqueeze(1) # batch, 1, n_ind_max, input_size\n",
    "        \n",
    "        mask2 = (labels.sum(dim=-1) == 0)\n",
    "\n",
    "        labels = torch.abs(labels).unsqueeze(1)        # batch, 1, n_ind_max, input_size\n",
    "        assert torch.equal(mask1, mask2)\n",
    "        # print(mask1.sum().item()/mask1.numel())\n",
    "\n",
    "        class_location = torch.arange(num_classes).long().unsqueeze(0).unsqueeze(-1).unsqueeze(-1).to(device) # batch, num_classes, 1, 1\n",
    "\n",
    "        labels = labels.unsqueeze(4).unsqueeze(4).unsqueeze(4).expand(-1, -1, -1, -1, 3, 3, 3, -1)\n",
    "        class_location = F.one_hot(class_location, num_classes=num_classes).unsqueeze(4).unsqueeze(4).unsqueeze(-1).expand(-1, -1, -1, -1, 3, 3, -1, 3)\n",
    "        refs = F.one_hot(refs, num_classes=num_classes).unsqueeze(4).unsqueeze(-1).unsqueeze(-1).expand(-1, -1, -1, -1, 3, -1, 3, 3)\n",
    "        SOI = F.one_hot(SOI, num_classes=num_classes).unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(-1, -1, -1, -1, -1, 3, 3, 3)\n",
    "\n",
    "        ref_sim = labels * class_location * refs * SOI\n",
    "        ref_sim = ref_sim.reshape(*ref_sim.shape[:4], -1).float() #batch, num_classes, n_ind_max, input_size, num_classes ** 3\n",
    "\n",
    "        ref_sim = ref_sim @ Transition.to(device) #batch, num_classes, n_ind_max, input_size, n_embd\n",
    "        \n",
    "        ####\n",
    "        # ref_sim_avg = ref_sim.mean(dim=-1, keepdim=True)\n",
    "        # below line assumes constant recombination rate.  positions should be in morgans not bp\n",
    "        positions = (positions - positions[:,input_size // 2].unsqueeze(-1)).abs()\n",
    "        admix_time = params[:,1].unsqueeze(-1)\n",
    "        # pos_probs = (1 - positions) ** (2 * admix_time)\n",
    "        # print(pos_probs.shape)\n",
    "        # fix this ?? # assume large population size unless otherwise specified? \n",
    "        N = 1000 \n",
    "        lam = 2 * N * (1 - torch.exp(-admix_time / (2 * N)))\n",
    "        pos_probs = torch.exp(-lam * positions) # * 0.5 + 0.5\n",
    "        # print(pos_probs.shape)\n",
    "        # print(pos_probs[0, 200:300])\n",
    "        # print()\n",
    "        pos_probs = pos_probs.unsqueeze(1).unsqueeze(1).unsqueeze(-1).expand(-1, num_classes, n_ind_max, -1, -1)\n",
    "        positions = positions.unsqueeze(1).unsqueeze(1).unsqueeze(-1).expand(-1, num_classes, n_ind_max, -1, -1)\n",
    "        ref_sim = torch.cat((ref_sim, positions, pos_probs), dim=-1) #batch, num_classes, n_ind_max, input_size, n_embd_model\n",
    "        ####\n",
    "\n",
    "        # Add noise\n",
    "        # if self.training:\n",
    "        #     ref_sim += torch.randn(ref_sim.shape).to(device) * sigma\n",
    "\n",
    "        mask1 = mask1.unsqueeze(1).unsqueeze(-1).repeat(1, num_classes, 1, 1, n_embd_model)\n",
    "        ref_sim[mask1] = 0\n",
    "\n",
    "\n",
    "        # include position encoding here?\n",
    "        # include frequency of each value here?\n",
    "\n",
    "        # dist_avg = ref_sim.mean(dim=1, keepdim=True) # batch, 1, input_size, 4\n",
    "        # ref_sim = torch.cat((ref_sim, dist_avg), dim=1) # batch, num_classes * n_ind_pan_model + 1, input_size, 4\n",
    "\n",
    "        ref_sim = self.linear0(ref_sim)\n",
    "        # ref_sim = self.relu(ref_sim)\n",
    "\n",
    "        # final classification layers\n",
    "        # ref_sim = self.block(ref_sim) ###\n",
    "        ref_sim = ref_sim.reshape(*ref_sim.shape[:3], -1) # batch, num_classes, n_ind_max, input_size * hidden0\n",
    "        ref_sim = self.linear1(ref_sim)\n",
    "        ref_sim = self.relu(ref_sim)\n",
    "        ref_sim = self.linear2(ref_sim)\n",
    "        ref_sim = self.relu(ref_sim)\n",
    "        ref_sim = self.linear3(ref_sim) # batch, num_classes, num_classes * n_ind_pan_model\n",
    "\n",
    "        # can pad inputs with less than 100 ref panels here instead of before to run faster\n",
    "        # pad them with trained output of padded sequence\n",
    "        # can encode class type (heterozygous or homozygous) here\n",
    "        ref_sim, _ = torch.sort(ref_sim, dim=2) \n",
    "        ref_sim = self.sigmoid(ref_sim).squeeze(-1) # batch, num_classes, num_classes * n_ind_pan_model\n",
    "        ref_sim = self.linear4(ref_sim)\n",
    "        ref_sim = self.relu(ref_sim)\n",
    "        ref_sim = self.linear5(ref_sim) # batch, num_classes, 1\n",
    "        ref_sim = ref_sim.squeeze(-1)\n",
    "\n",
    "        return ref_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dff33dfb-34ed-478c-8388-040cadcc2ab4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[3, 48, 501]' is invalid for input of size 24048",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(num_classes)\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     27\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mrepeat(refs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m, n_ind_pan_model, input_size)\n\u001b[0;32m---> 29\u001b[0m refs_batch \u001b[38;5;241m=\u001b[39m \u001b[43mrefs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_ind_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mreshape(labels\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], n_ind_max, input_size)\n\u001b[1;32m     31\u001b[0m labels \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mone_hot(labels\u001b[38;5;241m.\u001b[39mlong(), num_classes\u001b[38;5;241m=\u001b[39mnum_classes)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[3, 48, 501]' is invalid for input of size 24048"
     ]
    }
   ],
   "source": [
    "model = eval(model_name)()\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(\"full_seq_refalt.pth\", map_location=torch.device(device)))\n",
    "model.eval()\n",
    "\n",
    "random_file = 0 if human_data else 5\n",
    "\n",
    "y = convert_split(split_dir + \"split_\" + str(random_file), positions)\n",
    "y = torch.tensor(y) # 2 * n_ind_adm, len_seq\n",
    "y = y[0] + y[1] # len_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cfe79a0-3cae-4999-939f-ba0f6692db99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 501])\n",
      "torch.Size([501])\n",
      "torch.Size([501])\n",
      "torch.Size([3, 48, 167])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, positions = convert_panel(panel_dir + \"panel_\" + str(random_file))\n",
    "X = torch.tensor(X).to(device)[0] # len_seq\n",
    "positions = torch.tensor(positions).to(device) # len_seq\n",
    "\n",
    "refA, refB, _ = convert_panel_template(panel_template_dir + \"panel_template_\" + str(random_file)) \n",
    "\n",
    "refA = torch.tensor(refA) #num_files, n_ind_pan, input_size\n",
    "refB = torch.tensor(refB) #num_files, n_ind_pan, input_size\n",
    "refs = torch.zeros((num_classes, n_ind_pan_model, refA.shape[-1]))\n",
    "refs[0] = refA[:2 * n_ind_pan // 6 * 2:2] + refA[1:2 * n_ind_pan // 6 * 2:2]\n",
    "refs[2] = refB[:2 * n_ind_pan // 6 * 2:2] + refB[1:2 * n_ind_pan // 6 * 2:2]\n",
    "refs[1] = refA[-(n_ind_pan // 6 * 2):] + refB[-(n_ind_pan // 6 * 2):]\n",
    "\n",
    "labels = torch.arange(num_classes).to(device).unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "labels = labels.repeat(refs.shape[0], 1, n_ind_pan_model, input_size)\n",
    "\n",
    "print(refs.shape)\n",
    "print(X.shape)\n",
    "\n",
    "refs_batch = refs.reshape(refs.shape[0], n_ind_max, input_size)\n",
    "labels = labels.reshape(labels.shape[0], n_ind_max, input_size)\n",
    "labels = F.one_hot(labels.long(), num_classes=num_classes)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(positions.shape)\n",
    "print(refs.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52fefcdb-d98d-4cfa-8e9b-61deaef9bd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a916f52-7058-4c6a-89e6-0cfad47869f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([501])\n",
      "torch.Size([501])\n",
      "torch.Size([501])\n",
      "torch.Size([3, 48, 167])\n",
      "torch.Size([3, 48, 501, 3])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(positions.shape)\n",
    "print(refs.shape)\n",
    "print(labels.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993dd905-0bce-4602-8ec1-af2e6aeab129",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
